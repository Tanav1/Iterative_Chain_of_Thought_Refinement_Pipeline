{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNdQ1GaB6QBf1y+CC1u9NEw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEq25OH_UkKx",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1741468257779,
          "user_tz": 300,
          "elapsed": 93971,
          "user": {
            "displayName": "Tanav Thanjavuru",
            "userId": "04096199441511788161"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "323d9b91-70fd-4412-c876-6bc933c2a820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.3.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.13)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n",
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.5.1+cu124)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.48.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert_score\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bert_score-0.3.13 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.45.3\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.5.1+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.48.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.3.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "# !pip install datasets\n",
        "# !pip install evaluate\n",
        "# !pip install bert_score\n",
        "# !pip install bitsandbytes\n",
        "# !pip install peft\n",
        "# # !pip install -U bitsandbytes\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import evaluate\n",
        "import bitsandbytes\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from bert_score import score as bert_score\n",
        "from datasets import load_dataset\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "\n",
        "from peft import (\n",
        "    PeftModel,\n",
        "    PeftConfig,\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        "    TaskType\n",
        ")\n"
      ],
      "metadata": {
        "id": "7eOSzpnO7DcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j2GV0NEmVc9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_llama_model():\n",
        "    model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    return model, tokenizer\n",
        "\n",
        "def preprocess_datasets():\n",
        "    openbookqa = load_dataset(\"openbookqa\", \"main\")\n",
        "    reveal = load_dataset(\"google/reveal\")\n",
        "\n",
        "    def filter_bad_chains(example):\n",
        "        if 'explanation' in example and example['explanation']:\n",
        "            return len(example['explanation'].split()) > 5\n",
        "        return False\n",
        "\n",
        "    filtered_openbookqa = openbookqa.filter(filter_bad_chains)\n",
        "    return filtered_openbookqa, reveal\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bECU5E34Uqgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !huggingface-cli login\n"
      ],
      "metadata": {
        "id": "59D9N2rm8kuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llama_model, llama_tokenizer = load_llama_model()\n"
      ],
      "metadata": {
        "id": "f3Asdza9Uu0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_openbookqa, dataset_reveal = preprocess_datasets()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497,
          "referenced_widgets": [
            "decc117103c54b71a899b2b40a04f72b",
            "73c0adf851424ceba097bb9bb7bec07b",
            "0723526fa11e47779729f13281267ad4",
            "20d08d318b2f471c88d73778030ebac0",
            "7e7272512a4843dc9a549b8106452247",
            "c224c59ce17246dbb71a97bfab1a0090",
            "8c0c11d3b9e343b78dd125cabbd1bdfe",
            "cc44f97d5efa4040bf04ce06ea3c7052",
            "67787115cba34b4bb6edcf8ac3a1f2a0",
            "adf85aeb28cb48d8b5155fc526933261",
            "eb99429725a04e2a8b1c27bad17f22ca",
            "216ea407acbd4af1b394a3a7fa736c85",
            "8c6572370d3e42ccaf5190421d117ad0",
            "f3c0888fa1ea40b6a827a72a918cf6ee",
            "b372a1edb26d4301b5e7df3a74f905d3",
            "3bc364c6916c44dbb16784e22c288d4e",
            "a54ca9c974224c8f8781536b3a545e98",
            "3b8b38fbc0de4af984d5951687a6ba10",
            "51ddb7e769234f4082d552336387c89d",
            "6f1c19f1c0934caeb5fc6348573bc2a7",
            "e4e3e13d897a431daffda2974226bb15",
            "035e339fd9f645d3a9f0abd891e663b2",
            "28db7cb9127840edbd5218d1ced77c6b",
            "3348df481b1c47b28212acb00b52cc80",
            "f0c09b9caed942aa92782ba067f41fef",
            "ae18e4ed8f464bd6b2ac9dc9cd4940a0",
            "f2cffd359b694dd08d6ca77acc764c23",
            "fb0d633676164180a93cd37ef22ebc69",
            "a62796c561634aafbf5430136dbd287f",
            "941c01368165409baae9f4388c381d4b",
            "06a4a0f65bf54f198096050f38be8a57",
            "09e58250dbf04e248d49a8dccff7a47d",
            "dbb73e95659f4265a00b667a40b553d9",
            "35b726cd839b4674aee048b0f7dcf0d0",
            "a6945f58a67746b2b776008898b1b23d",
            "0dcdb4cad4af417d86d62c928c0a3987",
            "900988b47c7a49aabdde63ebb2e63a02",
            "107c227225064cee91d01a46f197bdeb",
            "c42fbed924704f9abc058cc6ea835803",
            "c299f3e5baab4c10a1bd1546d4feeccc",
            "1203ed747b77466e9e149c840d9e2238",
            "5fdbbaa1d07547b884e255032309f83d",
            "fc89bc3d25d54f7d927abbbf8578d0b8",
            "028753fd673c4095a43f0447f1cfecd2",
            "acbaf73e0ea54a24a66436548238dcae",
            "023a8c0d782b4e35a5c12581b6ad6d35",
            "d813b14ba2e44b20b278070991fc14a7",
            "3ebcab3074494750978a8797f585abfa",
            "9812cad0e9154864b160159b06f5d27a",
            "bb566c3db18d494ea38bc137b4be5f36",
            "eda02ffa76cb470db3623c9c25e90c10",
            "b34a31fd46e94de79e1620c19a3bb8c1",
            "04ec7917201840c091ebd83072061162",
            "ee0f9b110f6e4f2fa310da86fa1d330b",
            "a48d77cd2c78436abfff5e16f341cc32",
            "f239c962fa0e4055b6f98442d5574409",
            "f6998c059d934284bc9a4748fd313348",
            "f8b85272becb42f0bb16b1a3745ee64a",
            "e8fd8df1785749e3936537e5abf97c92",
            "b1e1b59dc3864a07b0ecc1c4cfa2b10f",
            "6ea1b2a07d7141bca28e5cc1c8847b7d",
            "c0c3d975e0094dd2b26077570b3035f9",
            "f0270a2f62e0487da8c78684b7cf751e",
            "69515f2146604e9587cff6b6ea5f61ee",
            "4adc280822f243db8ab1d83736ca4c89",
            "84b1bf0107a74daeba9fd6a15ed49458",
            "4b07c2850df54245b91f765981476d10",
            "9307f547b1ad4a4aba556ac87b43dd84",
            "c947545c57c14d56980bec7feda4b249",
            "89c37fdb1ed54851a43b8eae10e8dac3",
            "0392287df01f47feaab5fdd19fbf35c8",
            "bc2f2c37f5ce41a8a4fe5f269de6b85c",
            "319b7e0658d14346af694f2877403a55",
            "6f045507a94c463eb985ec46da4293d9",
            "42207552aefd477e86784b522b14b9d0",
            "439923ee78e446b2ade29826b761b229",
            "7a5964754cc6491c8bd3d1438ffab2cc",
            "7ac0b79d027b4ecca523a8375110dd0a",
            "134ec3c401ec471890a181cdeebe4d62",
            "1dc29087ac10452398a7e2e10027b26a",
            "00d8091f2d1a4b7fb9ee0fc7ba045053",
            "417115e7b28c42838fcc7b9f44207b7c",
            "bc95b8cbaed94610b885b270bcf1e5e0",
            "083e5dd0693d4c7b941f02efbdb5850f",
            "0f807c7b1f4a4a25a5c193a66f4633f4",
            "afb965a786e44d8c8d262a07cf9acf0c",
            "5e30b447260e4f1d928b59dcf39f01f2",
            "ef7f6979e76e42758d8622b564ce460d",
            "495de5954ffe4773a016771aac674346",
            "0360a09359cf4c919882f16dee470231",
            "f882228c32644db1bb1ee88f16c74e4b",
            "7dce8e3f6edb4e769ec4641db3632281",
            "6d73f9a228cd4ecea6e96b94b9d665ed",
            "092233bf5f484ad6bd1cba3702fff6cd",
            "499af33ecc53433b860fa931567a7f06",
            "05f013d03c99410c843df04fd0dfac6f",
            "17a6f41a93a847f9ba8bca14aef5aa22",
            "b0765697052d4689a17b1fe0b2604d5d",
            "a3050579886046089d82aa5b4ab49639",
            "c74e0971e4464054b645439c0651cfb5",
            "ce14e8924ab24251bba9f82a3dc34db4",
            "e5b46861d14f4f1daa28caec787972f7",
            "59ba6edc250940b69e7876aefc0f88cc",
            "91d7d9fbccb3408b8bf0a3f55653e524",
            "f49a8dbcd77e4006a1093610d50a73ca",
            "593e9bd6e5774ba3a60a5bcc6564dda3",
            "7999e0b3d6264f61bfbe6077fa40c520",
            "ac0fd7d2618e40ffb88cc764cc349344",
            "42d8c38eaf3f4feab0919af527741714",
            "c03f632d009946f2997a0cb48de334a9",
            "d44d046a59a44f498d67d7eb81dd0e05",
            "a3958dd29e32469b907926d05935d5b0",
            "41bfd1c800e542739b9d97b5aa642c3c",
            "cf1e6d8c9c2f4f14ad083b77a105e19f",
            "b6aa35c08e1e4d1e8bfe088de02d745c",
            "617d55000d5c49378d4b224bd7988997",
            "a369903a14d2486ab433c97acd05f48b",
            "2bcc766e614b47f886c4f74c293e703d",
            "75f8dcbd2fa84bfa91f0e676ea4fc7c8",
            "94fb3f5d30a74266a3c7e2331810b680",
            "7085bd09b29c4dc9afe617057de34233",
            "5d25296da7224ce0a62452be99970399",
            "6509d2452bb64b1d862e41a4144048d7",
            "c5a302cffe9d48758d86235f3f2ddde0",
            "aad158a142194e40bd5e0554f1a57b78",
            "4b5e0b66d5244463b581471b29007491",
            "52d61cbead2e4595a87aec88f5b1c17a",
            "c4ddf2f367be497aa1c965cae2bd8dc5",
            "025d212403134891a6ee03dfec5d2dd9",
            "20dc3962f12640b9b208df04265927c5",
            "71967b07d4ac451f9430c854fb58d881",
            "07c91f291ed94f83b49cd32d38340d7e",
            "91ec805a29e84104bbbbc343c729b245",
            "a03fdbe8c1f54388981a24289aa8e4ae",
            "2e52ff5eceb84da1857d7110dae8e57a",
            "bbe0ed8b807c468f81de043f7e29dc50",
            "f87590f83b2041059042f5b3ad70b855",
            "9a48ed324b4e4b4796af8170a0a94d7b",
            "0e214328b6264383b26a5df62bb3b55b",
            "21a3d12b5cf44ee8969f474150c2ae45",
            "01f32214c6574ae290c14bd4b3735ac9",
            "de03c717a27e4b93a62c404aea5db00e",
            "ec4aa7725c4b42f69d643c1fffd5497d",
            "82d004bb3a134fe895c318985bbd6e1f",
            "4e23de037ac8430996acb2710d8cb1c8",
            "b6a4853dce6d47b098120957cbaf127b",
            "bae2754a5448428ba0789f6bc6b84030",
            "25e3d60ccf83471f883cde83e94be1dd",
            "c87f6ec39dcf4edfb0bb0ea780c4de14",
            "7e57ed5c038b4802b17f87bf891a28a1",
            "1e908016101748fe9430bdc0453bed0d",
            "c1d7fc5ebfd5411cb7942f79e80a6dc4",
            "908b7dc8094648d99007790e97cd5b66",
            "bf02891926ab4b5c9e5df4cf5e85288a",
            "f0c88b0369b04f49bacb9b62db36a82b",
            "d3800e191b5542baa28df137f27f135a",
            "e9b4c685eaee498080fc6e800507e6da",
            "dff2be3291f5456f89f38bcf56afe8e2",
            "16e501684a524c8185b261c8fd81aa9d",
            "e7e359e1ca8144ce9f6977171a350d3f",
            "cbb2962bea0e49c59f0601a27744a914",
            "3cedbdada8f64d5c90931edc347f0d05",
            "3f9beeb8d4af411fb15671766b054ead",
            "6665a84c45f148988ef0f8d17d684f97",
            "6b4d9e0da89a4d1e875a9aa4a3007fc6"
          ]
        },
        "id": "RqabIUlPVOWS",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1741468282020,
          "user_tz": 300,
          "elapsed": 6523,
          "user": {
            "displayName": "Tanav Thanjavuru",
            "userId": "04096199441511788161"
          }
        },
        "outputId": "3595a1f4-1b96-4efb-92bd-103b5b8d2b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/9.06k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "decc117103c54b71a899b2b40a04f72b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/496k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "216ea407acbd4af1b394a3a7fa736c85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/58.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28db7cb9127840edbd5218d1ced77c6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/55.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35b726cd839b4674aee048b0f7dcf0d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/4957 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acbaf73e0ea54a24a66436548238dcae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f239c962fa0e4055b6f98442d5574409"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b07c2850df54245b91f765981476d10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ac0b79d027b4ecca523a8375110dd0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "reveal_eval.csv:   0%|          | 0.00/11.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "495de5954ffe4773a016771aac674346"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "reveal_open.csv:   0%|          | 0.00/2.75M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c74e0971e4464054b645439c0651cfb5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating eval split:   0%|          | 0/4956 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d44d046a59a44f498d67d7eb81dd0e05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating open split:   0%|          | 0/1146 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d25296da7224ce0a62452be99970399"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/4957 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91ec805a29e84104bbbbc343c729b245"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82d004bb3a134fe895c318985bbd6e1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0c88b0369b04f49bacb9b62db36a82b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_reveal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ5J3CP3-qCB",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1741468282065,
          "user_tz": 300,
          "elapsed": 44,
          "user": {
            "displayName": "Tanav Thanjavuru",
            "userId": "04096199441511788161"
          }
        },
        "outputId": "07432863-8be0-42ed-e0e0-b9f7893aff08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    eval: Dataset({\n",
            "        features: ['dataset', 'question', 'question_id', 'answer_model', 'step_idx', 'full_answer', 'step', 'decontextualized_step', 'attribution_relevance_label', 'attribution_relevance_majority', 'attribution_relevance_annotations', 'attribution_relevance_raters', 'attribution_relevance_num_ratings', 'evidence_id', 'evidence', 'attribution_label', 'attribution_majority', 'attribution_annotations', 'attribution_raters', 'attribution_num_ratings', 'attribution_justifications', 'annotated_in_attribution_batch', 'type_label', 'type_majority', 'type_annotations', 'type_raters', 'type_num_ratings', 'logic_relevance_label', 'logic_relevance_majority', 'logic_relevance_annotations', 'logic_relevance_raters', 'logic_relevance_num_ratings', 'logic_justifications', 'annotated_in_logic_batch', 'correctness_label', 'correctness_majority', 'correctness_annotations', 'correctness_raters', 'correctness_num_ratings', 'answer_id', 'attribution_majority_all_evidences', 'attribution_majority_all_steps', 'logic_majority_all_steps', 'agreement_majority_all_steps', 'is_low_agreement_hard_case', 'contamination_identifier', 'is_final_rated_evidence_for_step', 'answer_is_fully_attributable', 'answer_is_logically_correct', 'answer_is_fully_attributable_and_correct'],\n",
            "        num_rows: 4956\n",
            "    })\n",
            "    open: Dataset({\n",
            "        features: ['dataset', 'question', 'question_id', 'answer_model', 'step_idx', 'full_answer', 'step', 'decontextualized_step', 'attribution_relevance_label', 'attribution_relevance_majority', 'attribution_relevance_annotations', 'attribution_relevance_raters', 'attribution_relevance_num_ratings', 'evidence_id', 'evidence', 'attribution_label', 'attribution_majority', 'attribution_annotations', 'attribution_raters', 'attribution_num_ratings', 'attribution_justifications', 'annotated_in_attribution_batch', 'type_label', 'type_majority', 'type_annotations', 'type_raters', 'type_num_ratings', 'logic_relevance_label', 'logic_relevance_majority', 'logic_relevance_annotations', 'logic_relevance_raters', 'logic_relevance_num_ratings', 'logic_justifications', 'annotated_in_logic_batch', 'correctness_label', 'correctness_majority', 'correctness_annotations', 'correctness_raters', 'correctness_num_ratings', 'answer_id', 'attribution_majority_all_evidences', 'attribution_majority_all_steps', 'logic_majority_all_steps', 'agreement_majority_all_steps', 'is_low_agreement_hard_case', 'contamination_identifier', 'is_final_rated_evidence_for_step', 'answer_is_fully_attributable', 'answer_is_logically_correct', 'answer_is_fully_attributable_and_correct'],\n",
            "        num_rows: 1146\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Format dataset for causal language modeling with improved prompting\n",
        "    def format_example(example):\n",
        "        # Only process examples with valid labels\n",
        "        if \"correctness_label\" not in example or example[\"correctness_label\"] is None:\n",
        "            return None\n",
        "\n",
        "        # Extract the relevant fields\n",
        "        question = example.get(\"question\", \"\")\n",
        "        step = example.get(\"step\", \"\")\n",
        "\n",
        "        # Determine if this is a logical step (reasoning) or attribution step (factual)\n",
        "        step_type = example.get(\"type_label\", \"Unknown step type\")\n",
        "        is_logical_step = \"Logical\" in step_type\n",
        "\n",
        "        # Get previous steps if available\n",
        "        # This is a simplification - in a real implementation, you'd need to collect all previous steps for this question\n",
        "        previous_steps_text = \"\"\n",
        "\n",
        "        # Check if we have full_answer to extract context\n",
        "        if \"full_answer\" in example:\n",
        "            full_answer = example[\"full_answer\"]\n",
        "            # Find the current step in the full answer\n",
        "            if step in full_answer:\n",
        "                # Extract the part of the answer up to the current step\n",
        "                step_index = full_answer.find(step)\n",
        "                previous_text = full_answer[:step_index].strip()\n",
        "                if previous_text:\n",
        "                    # Split by periods or newlines to get approximate steps\n",
        "                    sentences = [s.strip() for s in previous_text.replace('\\n', '. ').split('. ') if s.strip()]\n",
        "                    if sentences:\n",
        "                        previous_steps_text = \"Previous steps:\\n\" + \"\\n\".join(f\"- {s}\" for s in sentences if s) + \"\\n\\n\"\n",
        "\n",
        "        # Create more explicit instruction based on step type\n",
        "        if is_logical_step:\n",
        "            instruction = (\n",
        "                \"You are a reasoning verifier. Your task is to determine if a reasoning step is logically correct \"\n",
        "                \"given the context of a question and previous reasoning steps. Focus on whether the step follows \"\n",
        "                \"logically from what came before, not just whether it's factually accurate on its own.\"\n",
        "            )\n",
        "        else:\n",
        "            instruction = (\n",
        "                \"You are a reasoning verifier. Your task is to determine if a reasoning step is valid \"\n",
        "                \"given the context of a question. Evaluate whether the step is reasonable and contributes \"\n",
        "                \"to answering the question.\"\n",
        "            )\n",
        "\n",
        "        # Include a few-shot example to guide the model\n",
        "        if is_logical_step:\n",
        "            few_shot_example = (\n",
        "    \"Example 1:\\n\"\n",
        "    \"Question: What is 5 + 7?\\n\"\n",
        "    \"Previous steps:\\n\"\n",
        "    \"- 5 + 7 can be calculated directly.\\n\"\n",
        "    \"Reasoning Step: The sum of 5 and 7 is 12.\\n\"\n",
        "    \"Is the reasoning step valid? Yes, this reasoning step is valid.\\n\\n\"\n",
        "\n",
        "    \"Example 2:\\n\"\n",
        "    \"Question: How many planets are in our solar system?\\n\"\n",
        "    \"Previous steps:\\n\"\n",
        "    \"- There are 8 recognized planets in our solar system.\\n\"\n",
        "    \"- Pluto used to be considered the 9th planet.\\n\"\n",
        "    \"Reasoning Step: Therefore, there are 9 planets in our solar system.\\n\"\n",
        "    \"Is the reasoning step valid? No, this reasoning step is invalid. The previous step states that Pluto is no longer considered a planet.\\n\\n\"\n",
        "\n",
        "    \"Example 3:\\n\"\n",
        "    \"Question: If microchip makers didn't keep trying to shrink their chips, how fast could your average home computer be by now?\\n\"\n",
        "    \"Previous steps:\\n\"\n",
        "    \"- The speed of a computer is determined by the number of transistors on the chip.\\n\"\n",
        "    \"- The number of transistors on a chip is inversely proportional to the size of each transistor.\\n\"\n",
        "    \"Reasoning Step: Thus, if microchip makers didn't keep trying to shrink their chips, there would be fewer transistors, resulting in slower computers.\\n\"\n",
        "    \"Is the reasoning step valid? Yes, this reasoning step is valid. It correctly follows from the previous steps about the relationship between transistor size and computer speed.\\n\\n\"\n",
        "\n",
        "    \"Example 4:\\n\"\n",
        "    \"Question: What would happen to Earth's climate if the sun suddenly became twice as bright?\\n\"\n",
        "    \"Previous steps:\\n\"\n",
        "    \"- The sun provides most of Earth's energy input.\\n\"\n",
        "    \"- Earth's temperature is determined by the balance of incoming and outgoing radiation.\\n\"\n",
        "    \"Reasoning Step: If the sun became twice as bright, Earth's climate would cool down dramatically.\\n\"\n",
        "    \"Is the reasoning step valid? No, this reasoning step is invalid. If the sun became twice as bright, more energy would reach Earth, leading to warming, not cooling.\\n\\n\"\n",
        "\n",
        "    \"Example 5:\\n\"\n",
        "    \"Question: How would a universal basic income affect poverty rates?\\n\"\n",
        "    \"Previous steps:\\n\"\n",
        "    \"- A universal basic income provides regular payments to all citizens regardless of work status.\\n\"\n",
        "    \"- Poverty is defined as income below a certain threshold.\\n\"\n",
        "    \"- Some current welfare programs are means-tested and phase out as income increases.\\n\"\n",
        "    \"Reasoning Step: Therefore, a universal basic income would eliminate all poverty instantly.\\n\"\n",
        "    \"Is the reasoning step valid? No, this reasoning step is invalid. While a UBI would provide income, the conclusion that it would eliminate all poverty is too strong and doesn't follow logically from the previous steps, which don't specify the amount of UBI or how it compares to poverty thresholds.\\n\\n\"\n",
        ")\n",
        "        else:\n",
        "            few_shot_example = (\n",
        "    \"Example 1:\\n\"\n",
        "    \"Question: What is the capital of France?\\n\"\n",
        "    \"Reasoning Step: Paris is the capital of France.\\n\"\n",
        "    \"Is the reasoning step valid? Yes, this reasoning step is valid.\\n\\n\"\n",
        "\n",
        "    \"Example 2:\\n\"\n",
        "    \"Question: What is 2+2?\\n\"\n",
        "    \"Reasoning Step: 2+2=5\\n\"\n",
        "    \"Is the reasoning step valid? No, this reasoning step is invalid.\\n\\n\"\n",
        "\n",
        "    \"Example 3:\\n\"\n",
        "    \"Question: How many bones are in the human body?\\n\"\n",
        "    \"Reasoning Step: The adult human skeleton contains 206 bones, though this number varies slightly between individuals.\\n\"\n",
        "    \"Is the reasoning step valid? Yes, this reasoning step is valid. It correctly states the standard number of bones in an adult human.\\n\\n\"\n",
        "\n",
        "    \"Example 4:\\n\"\n",
        "    \"Question: What causes ocean tides?\\n\"\n",
        "    \"Reasoning Step: Ocean tides are primarily caused by the gravitational forces exerted by the sun and stars.\\n\"\n",
        "    \"Is the reasoning step valid? No, this reasoning step is invalid. Tides are primarily caused by the gravitational forces of the moon and sun, not stars.\\n\\n\"\n",
        "\n",
        "    \"Example 5:\\n\"\n",
        "    \"Question: When did World War II end?\\n\"\n",
        "    \"Reasoning Step: World War II ended in Europe on May 8, 1945 (V-E Day) and in Asia on September 2, 1945 (V-J Day) when Japan formally surrendered.\\n\"\n",
        "    \"Is the reasoning step valid? Yes, this reasoning step is valid. It accurately presents the commonly accepted end dates of World War II in different theaters.\\n\\n\"\n",
        "\n",
        "    \"Example 6:\\n\"\n",
        "    \"Question: What happens during photosynthesis?\\n\"\n",
        "    \"Reasoning Step: During photosynthesis, plants convert water and oxygen into glucose and carbon dioxide using energy from sunlight.\\n\"\n",
        "    \"Is the reasoning step valid? No, this reasoning step is invalid. Photosynthesis converts water and carbon dioxide into glucose and oxygen, not the other way around.\\n\\n\"\n",
        ")\n",
        "\n",
        "        # Format the actual task\n",
        "        task = (\n",
        "            f\"Question: {question}\\n\"\n",
        "            f\"{previous_steps_text}\"\n",
        "            f\"Reasoning Step: {step}\\n\"\n",
        "            f\"Is the reasoning step valid?\"\n",
        "        )\n",
        "\n",
        "        # Create the target response based on correctness label\n",
        "        if example[\"correctness_label\"] == \"Correct\":\n",
        "            target = \" Yes, this reasoning step is valid.\"\n",
        "        else:\n",
        "            target = \" No, this reasoning step is invalid.\"\n",
        "\n",
        "        # Combine everything into the full prompt\n",
        "        full_prompt = f\"{instruction}\\n\\n{few_shot_example}{task}{target}</s>\"\n",
        "\n",
        "        return {\"input_text\": full_prompt, \"label\": example[\"correctness_label\"]}\n",
        "\n",
        "    # Apply formatting\n",
        "    formatted_dataset = eval_reveal.map(format_example)\n",
        "    formatted_dataset = formatted_dataset.filter(lambda x: x is not None)\n",
        "\n",
        "    print(f\"Total formatted examples: {len(formatted_dataset)}\")\n",
        "\n",
        "    # Sample and print a few examples to verify formatting\n",
        "    print(\"\\nSample formatted examples:\")\n",
        "    for i in range(min(3, len(formatted_dataset))):\n",
        "        print(f\"Example {i+1}:\\n{formatted_dataset[i]['input_text'][:500]}...\\n\")\n",
        "\n",
        "    # Analyze label distribution\n",
        "    correct_count = sum(1 for item in formatted_dataset if item[\"label\"] == \"Correct\")\n",
        "    incorrect_count = sum(1 for item in formatted_dataset if item[\"label\"] == \"Incorrect\")\n",
        "    print(f\"Label distribution:\")\n",
        "    print(f\"  Correct: {correct_count} ({correct_count/len(formatted_dataset)*100:.2f}%)\")\n",
        "    print(f\"  Incorrect: {incorrect_count} ({incorrect_count/len(formatted_dataset)*100:.2f}%)\")\n",
        "\n",
        "    # Tokenize the dataset for causal LM\n",
        "    def tokenize_example(example):\n",
        "        # Tokenize with padding and truncation\n",
        "        tokenized = verifier_tokenizer(\n",
        "            example[\"input_text\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=768,  # Increased max length to accommodate the examples\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        input_ids = tokenized[\"input_ids\"][0]\n",
        "        attention_mask = tokenized[\"attention_mask\"][0]\n",
        "\n",
        "        # Set up labels for causal LM\n",
        "        labels = input_ids.clone()\n",
        "        labels[labels == verifier_tokenizer.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels\n",
        "        }\n",
        "\n",
        "    tokenized_dataset = formatted_dataset.map(\n",
        "        tokenize_example,\n",
        "        remove_columns=[\"input_text\", \"label\"]\n",
        "    )\n",
        "\n",
        "    # Balance the dataset to have equal numbers of valid and invalid examples\n",
        "    valid_examples = [ex for i, ex in enumerate(tokenized_dataset) if formatted_dataset[i][\"label\"] == \"Correct\"]\n",
        "    invalid_examples = [ex for i, ex in enumerate(tokenized_dataset) if formatted_dataset[i][\"label\"] == \"Incorrect\"]\n",
        "\n",
        "    print(f\"Valid examples: {len(valid_examples)}\")\n",
        "    print(f\"Invalid examples: {len(invalid_examples)}\")\n",
        "\n",
        "    # To balance, take the minimum count and sample from the larger group\n",
        "    min_count = min(len(valid_examples), len(invalid_examples))\n",
        "    balanced_count = min(min_count, 3000)  # Cap at 3000 examples per class to keep training manageable\n",
        "\n",
        "    # Sample from both groups to create a balanced dataset\n",
        "    import random\n",
        "    random.seed(42)\n",
        "    if len(valid_examples) > balanced_count:\n",
        "        valid_examples = random.sample(valid_examples, balanced_count)\n",
        "    else:\n",
        "        valid_examples = valid_examples[:balanced_count]\n",
        "\n",
        "    if len(invalid_examples) > balanced_count:\n",
        "        invalid_examples = random.sample(invalid_examples, balanced_count)\n",
        "    else:\n",
        "        invalid_examples = invalid_examples[:balanced_count]\n",
        "\n",
        "    # Combine and shuffle the balanced examples\n",
        "    balanced_examples = valid_examples + invalid_examples\n",
        "    random.shuffle(balanced_examples)\n",
        "\n",
        "    print(f\"Total balanced examples: {len(balanced_examples)}\")\n",
        "\n",
        "    # Split into train and validation sets\n",
        "    train_data, val_data = train_test_split(balanced_examples, test_size=0.15, random_state=42)\n",
        "\n",
        "    print(f\"Training examples: {len(train_data)}\")\n",
        "    print(f\"Validation examples: {len(val_data)}\")\n",
        "\n",
        "    # Training arguments - optimized for memory efficiency but with longer training\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./gemma_verifier_enhanced_lora_100_epoch\",\n",
        "        evaluation_strategy=\"steps\",\n",
        "        eval_steps=100,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=100,\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=16,  # Larger effective batch size\n",
        "        per_device_eval_batch_size=1,\n",
        "        learning_rate=1e-4,\n",
        "        weight_decay=0.01,\n",
        "        warmup_ratio=0.1,\n",
        "        save_total_limit=3,\n",
        "        load_best_model_at_end=True,\n",
        "        fp16=True,  # Use FP16 during training\n",
        "        logging_steps=10,\n",
        "        num_train_epochs=num_epochs,  # More epochs\n",
        "        report_to=\"none\"  # Disable wandb or other reporting tools if not needed\n",
        "    )\n",
        "\n",
        "    # Create data collator\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=verifier_tokenizer,\n",
        "        mlm=False  # We're doing causal language modeling, not masked language modeling\n",
        "    )\n",
        "\n",
        "    # Create trainer\n",
        "    trainer = Trainer(\n",
        "        model=verifier_model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_data,\n",
        "        eval_dataset=val_data,\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=verifier_tokenizer\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the model with all necessary components\n",
        "    peft_model_path = \"./gemma_verifier_enhanced_lora_final_100_epoch\"\n",
        "    verifier_model.save_pretrained(peft_model_path)\n",
        "    verifier_tokenizer.save_pretrained(peft_model_path)\n",
        "\n",
        "    # Save adapter config separately to make loading easier\n",
        "    verifier_model.config.save_pretrained(peft_model_path)\n",
        "\n",
        "    # Define improved prediction function with context handling\n",
        "    def predict_validity(question, step, previous_steps=None, step_type=\"Unknown\"):\n",
        "        \"\"\"\n",
        "        Predict whether a reasoning step is valid.\n",
        "\n",
        "        Args:\n",
        "            question (str): The question being answered\n",
        "            step (str): The reasoning step to verify\n",
        "            previous_steps (list, optional): Previous reasoning steps\n",
        "            step_type (str, optional): Type of step (\"Logical step\" or \"Attribution step\")\n",
        "\n",
        "        Returns:\n",
        "            bool: True if the step is valid, False otherwise\n",
        "        \"\"\"\n",
        "        is_logical_step = \"Logical\" in step_type\n",
        "\n",
        "        # Format previous steps if provided\n",
        "        previous_steps_text = \"\"\n",
        "        if previous_steps and len(previous_steps) > 0:\n",
        "            previous_steps_text = \"Previous steps:\\n\" + \"\\n\".join(f\"- {s}\" for s in previous_steps if s) + \"\\n\\n\"\n",
        "\n",
        "        # Create appropriate instruction based on step type\n",
        "        if is_logical_step:\n",
        "            instruction = (\n",
        "                \"You are a reasoning verifier. Your task is to determine if a reasoning step is logically correct \"\n",
        "                \"given the context of a question and previous reasoning steps. Focus on whether the step follows \"\n",
        "                \"logically from what came before, not just whether it's factually accurate on its own.\"\n",
        "            )\n",
        "            few_shot_example = (\n",
        "                \"Example 1:\\n\"\n",
        "                \"Question: What is 5 + 7?\\n\"\n",
        "                \"Previous steps:\\n\"\n",
        "                \"- 5 + 7 can be calculated directly.\\n\"\n",
        "                \"Reasoning Step: The sum of 5 and 7 is 12.\\n\"\n",
        "                \"Is the reasoning step valid? Yes, this reasoning step is valid.\\n\\n\"\n",
        "                \"Example 2:\\n\"\n",
        "                \"Question: How many planets are in our solar system?\\n\"\n",
        "                \"Previous steps:\\n\"\n",
        "                \"- There are 8 recognized planets in our solar system.\\n\"\n",
        "                \"- Pluto used to be considered the 9th planet.\\n\"\n",
        "                \"Reasoning Step: Therefore, there are 9 planets in our solar system.\\n\"\n",
        "                \"Is the reasoning step valid? No, this reasoning step is invalid. The previous step states that Pluto is no longer considered a planet.\\n\\n\"\n",
        "            )\n",
        "        else:\n",
        "            instruction = (\n",
        "                \"You are a reasoning verifier. Your task is to determine if a reasoning step is valid \"\n",
        "                \"given the context of a question. Evaluate whether the step is reasonable and contributes \"\n",
        "                \"to answering the question.\"\n",
        "            )\n",
        "            few_shot_example = (\n",
        "                \"Example 1:\\n\"\n",
        "                \"Question: What is the capital of France?\\n\"\n",
        "                \"Reasoning Step: Paris is the capital of France.\\n\"\n",
        "                \"Is the reasoning step valid? Yes, this reasoning step is valid.\\n\\n\"\n",
        "                \"Example 2:\\n\"\n",
        "                \"Question: What is 2+2?\\n\"\n",
        "                \"Reasoning Step: 2+2=5\\n\"\n",
        "                \"Is the reasoning step valid? No, this reasoning step is invalid.\\n\\n\"\n",
        "            )\n",
        "\n",
        "        # Format the task\n",
        "        task = (\n",
        "            f\"Question: {question}\\n\"\n",
        "            f\"{previous_steps_text}\"\n",
        "            f\"Reasoning Step: {step}\\n\"\n",
        "            f\"Is the reasoning step valid?\"\n",
        "        )\n",
        "\n",
        "        # Combine everything into the full prompt\n",
        "        input_text = f\"{instruction}\\n\\n{few_shot_example}{task}\"\n",
        "\n",
        "        inputs = verifier_tokenizer(input_text, return_tensors=\"pt\").to(verifier_model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = verifier_model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=40,\n",
        "                temperature=0.1,\n",
        "                do_sample=False,\n",
        "                top_p=0.95,\n",
        "            )\n",
        "\n",
        "        prediction = verifier_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Extract just the prediction part\n",
        "        response = prediction.split(\"Is the reasoning step valid?\")[-1].strip()\n",
        "\n",
        "        # Look for detailed explanation in the response\n",
        "        contains_explanation = len(response.split()) > 5\n",
        "\n",
        "        # Analyze the response for validity indicators\n",
        "        valid_indicators = [\"yes\", \"valid\", \"correct\", \"accurate\", \"true\"]\n",
        "        invalid_indicators = [\"no\", \"invalid\", \"incorrect\", \"wrong\", \"false\", \"error\", \"mistake\"]\n",
        "\n",
        "        # Check for clear validity indicators\n",
        "        has_valid = any(indicator in response.lower() for indicator in valid_indicators)\n",
        "        has_invalid = any(indicator in response.lower() for indicator in invalid_indicators)\n",
        "\n",
        "        # If we have both or neither, look for patterns like \"Yes, this reasoning step is valid\"\n",
        "        if (has_valid and has_invalid) or (not has_valid and not has_invalid):\n",
        "            # Look for specific phrases\n",
        "            if \"yes, this reasoning step is valid\" in response.lower():\n",
        "                return True\n",
        "            elif \"no, this reasoning step is invalid\" in response.lower():\n",
        "                return False\n",
        "\n",
        "            # If we have an explanation, do more nuanced analysis\n",
        "            if contains_explanation:\n",
        "                # Count positive vs negative indicators\n",
        "                valid_count = sum(response.lower().count(indicator) for indicator in valid_indicators)\n",
        "                invalid_count = sum(response.lower().count(indicator) for indicator in invalid_indicators)\n",
        "\n",
        "                if valid_count > invalid_count:\n",
        "                    return True\n",
        "                elif invalid_count > valid_count:\n",
        "                    return False\n",
        "\n",
        "            # Default to interpreting \"yes\" or \"no\" at the start\n",
        "            if response.lower().startswith(\"yes\"):\n",
        "                return True\n",
        "            elif response.lower().startswith(\"no\"):\n",
        "                return False\n",
        "\n",
        "        # If we only have valid indicators\n",
        "        if has_valid and not has_invalid:\n",
        "            return True\n",
        "\n",
        "        # If we only have invalid indicators\n",
        "        if has_invalid and not has_valid:\n",
        "            return False\n",
        "\n",
        "        # Fall back to a conservative approach\n",
        "        return False\n",
        "\n",
        "    return verifier_model, verifier_tokenizer, predict_validity\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def fine_tune_verifier(num_epochs=50):\n",
        "    # Load model and tokenizer in FP16 (no quantization)\n",
        "    model_name = \"google/gemma-2b\"\n",
        "\n",
        "    # Load model with FP16 (no quantization)\n",
        "    verifier_model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        torch_dtype=torch.float16,  # Use FP16 instead of quantization\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "    verifier_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Set padding token if needed\n",
        "    if verifier_tokenizer.pad_token is None:\n",
        "        verifier_tokenizer.pad_token = verifier_tokenizer.eos_token\n",
        "        verifier_model.config.pad_token_id = verifier_tokenizer.pad_token_id\n",
        "\n",
        "    # Enable gradient checkpointing to save memory\n",
        "    verifier_model.gradient_checkpointing_enable()\n",
        "\n",
        "    # Define LoRA configuration for Gemma\n",
        "    lora_config = LoraConfig(\n",
        "        r=8,  # Small rank to save memory\n",
        "        lora_alpha=16,\n",
        "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "        task_type=TaskType.CAUSAL_LM\n",
        "    )\n",
        "\n",
        "    # Apply LoRA to the model\n",
        "    verifier_model = get_peft_model(verifier_model, lora_config)\n",
        "\n",
        "    # Print trainable parameters info\n",
        "    verifier_model.print_trainable_parameters()\n",
        "\n",
        "    # Load REVEAL dataset\n",
        "    reveal = load_dataset(\"google/reveal\")\n",
        "\n",
        "    # Analyze the dataset\n",
        "    print(f\"Dataset splits: {reveal.keys()}\")\n",
        "    print(f\"Eval split size: {len(reveal['eval'])}\")\n",
        "    if 'open' in reveal:\n",
        "        print(f\"Open split size: {len(reveal['open'])}\")\n",
        "\n",
        "    # Filter out low-agreement annotations from eval split\n",
        "    eval_reveal = reveal[\"eval\"].filter(lambda example: not example.get(\"is_low_agreement_hard_case\", False))\n",
        "\n",
        "    # Ensure correctness_label exists and is valid before processing\n",
        "    eval_reveal = eval_reveal.filter(\n",
        "        lambda example: example.get(\"correctness_label\") is not None and\n",
        "                       isinstance(example.get(\"correctness_label\"), str)\n",
        "    )\n"
      ],
      "metadata": {
        "id": "kV1H2w8B-KPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   verifier_model, verifier_tokenizer, predict_validity = fine_tune_verifier()\n"
      ],
      "metadata": {
        "id": "28orVzYTXrp8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1741473306021,
          "user_tz": 300,
          "elapsed": 2319504,
          "user": {
            "displayName": "Tanav Thanjavuru",
            "userId": "04096199441511788161"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "67058be7ecec4169987174313fe2c289",
            "048db9f92c4f4ede889de6d90eea3a83",
            "61ec5848822047acaaa25956b7bf1c70",
            "4d736cf9cd944334994504ee4954d337",
            "9c16822341f3486ea9032dd8fedb0b6c",
            "6759aa40baed4444a904c6855c7ecdf0",
            "14e095723eb04464b87d360a67f03dc8",
            "2fec3f5d80024cc59f712b8ac2f8c663",
            "d9e148c79179461a8d74a3d64599de89",
            "23db83e9e7374ba5b4254c881256edcc",
            "ce8e2dd5ad3d426484960d7523d81a33"
          ]
        },
        "outputId": "2c0ef687-a46c-4748-dcd8-768004eb1025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67058be7ecec4169987174313fe2c289"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 1,843,200 || all params: 2,508,015,616 || trainable%: 0.0735\n",
            "Dataset splits: dict_keys(['eval', 'open'])\n",
            "Eval split size: 4956\n",
            "Open split size: 1146\n",
            "Total formatted examples: 1256\n",
            "\n",
            "Sample formatted examples:\n",
            "Example 1:\n",
            "You are a reasoning verifier. Your task is to determine if a reasoning step is logically correct given the context of a question and previous reasoning steps. Focus on whether the step follows logically from what came before, not just whether it's factually accurate on its own.\n",
            "\n",
            "Example 1:\n",
            "Question: What is 5 + 7?\n",
            "Previous steps:\n",
            "- 5 + 7 can be calculated directly.\n",
            "Reasoning Step: The sum of 5 and 7 is 12.\n",
            "Is the reasoning step valid? Yes, this reasoning step is valid.\n",
            "\n",
            "Example 2:\n",
            "Question: How ...\n",
            "\n",
            "Example 2:\n",
            "You are a reasoning verifier. Your task is to determine if a reasoning step is logically correct given the context of a question and previous reasoning steps. Focus on whether the step follows logically from what came before, not just whether it's factually accurate on its own.\n",
            "\n",
            "Example 1:\n",
            "Question: What is 5 + 7?\n",
            "Previous steps:\n",
            "- 5 + 7 can be calculated directly.\n",
            "Reasoning Step: The sum of 5 and 7 is 12.\n",
            "Is the reasoning step valid? Yes, this reasoning step is valid.\n",
            "\n",
            "Example 2:\n",
            "Question: How ...\n",
            "\n",
            "Example 3:\n",
            "You are a reasoning verifier. Your task is to determine if a reasoning step is logically correct given the context of a question and previous reasoning steps. Focus on whether the step follows logically from what came before, not just whether it's factually accurate on its own.\n",
            "\n",
            "Example 1:\n",
            "Question: What is 5 + 7?\n",
            "Previous steps:\n",
            "- 5 + 7 can be calculated directly.\n",
            "Reasoning Step: The sum of 5 and 7 is 12.\n",
            "Is the reasoning step valid? Yes, this reasoning step is valid.\n",
            "\n",
            "Example 2:\n",
            "Question: How ...\n",
            "\n",
            "Label distribution:\n",
            "  Correct: 1100 (87.58%)\n",
            "  Incorrect: 156 (12.42%)\n",
            "Valid examples: 1100\n",
            "Invalid examples: 156\n",
            "Total balanced examples: 312\n",
            "Training examples: 265\n",
            "Validation examples: 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-55e2cb86c202>:327: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [800/800 38:22, Epoch 47/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.162700</td>\n",
              "      <td>0.169101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.121700</td>\n",
              "      <td>0.138981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.104700</td>\n",
              "      <td>0.134835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.093900</td>\n",
              "      <td>0.137707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.083700</td>\n",
              "      <td>0.146900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.070300</td>\n",
              "      <td>0.167804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.064100</td>\n",
              "      <td>0.179298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.059400</td>\n",
              "      <td>0.189314</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}